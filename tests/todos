take into account that no matter how many dictionaries you stuff in there you can never get definitions for a word
if mecab doesn't recognize it as a word in itself
don't know for sure but first impressions i don't think it's viable for us to fix this

you think hard enough about this and you come to realize that maybe significant portions of it were ill-conceived
as in: might it not make more sense to figure out a way to insert ourselves somewhere in the space between
anki, ankiconnect and yomitan
st we can leverage yomitan to pick words and generate definitions and we only care about some logic re: whether word
is already in deck + what deck to put word in - and, of course, the sentence/audio/furigana generation

ankiconnect doesn't have hooks
but we could have a menu a lot like the w table where you toggle "intercept yomitan/chan card creation" or sth like that
put a hook on note creation, passthrough if it doesn't fit the yomitan/chan rq format
    (but print to console if this is the case - it's weird to have the toggle activated and be creating *other* cards...)
if it does fit, capture the request (rt True, None) and push it into the wordtable. bam, we have the word we want
+ definition, no need to use mecab or any of that
speaking of, will need to turn of lexical check, which is suspect
and there is still the issue of how tl quality in jesc/jparacrawl is rather ass even when qc'd - there was a todo about
this above, lemme find

...and wouldn't it be a good idea to do the common TODOs before we fork, actually?

...and thinking about it, i'm too lazy to do all the common TODOs and i know it'll be a pain to port them later so
it seems to me like the best choice is to just add more features to what we currently got
and pare things down later if necessary

TODO option to add machine translated sentences (tag them in db + gui)

still a reasonable amount of stuff to do, but primarily gui/config - let's make a list

todo figure out autoplay

TODO cleanup note creation, w a widget to pick which deck stuff goes to

other todos that are still relevant but not that urgent

TODO help menus

TODO port decks (incl. rtk to migaku... somehow?)

TODO set up hooks st if a deck is deleted the corresponding words in our db stop being marked as known
 there lurks there a more complicated question ab how much redundance there should be between the two dbs
 n_known_words and such are good for querying but is Keyword.known actually useful? if so, should we also store
 whether it's known in the ttbtr deck or one of the other ones? maybe we should store the note/card id, too, then?
 ...
 i think the right answer is to avoid enforced redundancy - simply not worth the hassle, seems like a smell even
 will need to set up the hooks mentioned above, though, which means a way to unmark words as known when removed
 to avoid updating every single row the flow should be
 get known words from db -> check against anki collection -> update what is necessary
 (this on top of the reverse flow that we already have implemented w the proper hooks)
 ...
 continuing on the above: no, even less redundancy is probably good
 after updating keyword.known we always call the update functions for the whole db, anyway
 so probably for the best to remove keyword.known altogether and just create temp tables for update whenever relevant
 ...
 but yk what, it's good to have known in the db st the spm can callback to know the comprehensibility of a sentence
 i think the best approach is to have keyword.known
 only have SentenceRepository (& its members) be aware of its existence, st SentenceRepository can handle the logic
 of when it needs to update its knowledge of what words are known (i.e. upon any query that will need this data)
 but simultaneously doing this checks a have_known_words_been_updated query which is handled by some class with
 its state hooked onto the relevant hooks (new cards created, card has been reviewed (mb only if its ivl was 0 before))
 etc
 ...
 but i'm pretty sure there's still some issue here with how mecab won't recognize all words we're interested in

TODO better db init: if no exist create w/o covering index, then insert, then create covering index

TODO segregate user_files content by active user - the config files, anyway, but not sentence.db or the big downloads

TODO type annotations, docs

TODO add new sentences menu (with semi automatic translations)

todos that are not relevant in lite

TODO there are some timeout issues - with the robots, I think? or maybe the translator? it's unclear but sometimes if
 you leave anki alone for a few minutes it throws an exception out of the blue

TODO if i put the bakamitai lyrics through the mine words widget - "I love you" (part of the lyrics) doesnt show in any
 of the boxes - where is it getting lost?

TODO config options for showing definitions on either language (i.e. monolingual mode toggle)
 -> the easiest way to accomplish this is to edit card html directly

TODO better dicts. either:
 no dicts at all
 get definitions and html from yomichan via selenium
 get definitions from yomichan via selenium and parse what we can
 get definitions from our own files and parse what we can
  note of the last two - parsing our own files is no harder than doing things through selenium and does NOT insert a
  massive dependency in the project - the only reason to go via selenium is to use yomichan dicts instead of redownload
  (yomichan files are not readily visible)

TODO main bits of gui
 standalone sentence adder
 the cards themselves (when do the notes get created? must be in the table gui, no?

TODO make it so it doesnt crash instantly if robots requests fail. Offline mode in general
 -> this should be easily fixable by making the robots sessions lazy